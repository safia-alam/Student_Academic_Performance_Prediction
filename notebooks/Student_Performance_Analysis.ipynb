{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d0972fd",
   "metadata": {},
   "source": [
    "# ðŸŽ“ Student Academic Performance Prediction â€” End-to-End ML\n",
    "**Author:** Safia Alam H B  \n",
    "**Goal:** Predict students' average exam score from demographic and academic features.\n",
    "\n",
    "## What you'll learn\n",
    "- Data loading with flexible column mapping\n",
    "- EDA (quick, practical)\n",
    "- Feature engineering (`average_score`, `pass_fail`)\n",
    "- Model comparison: Linear Regression, Random Forest, Gradient Boosting\n",
    "- Hyperparameter tuning with RandomizedSearchCV\n",
    "- Persisting the best pipeline to `models/best_model.pkl`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e396934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, json, math, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import joblib\n",
    "\n",
    "DATA_PATH = os.path.join(\"..\", \"data\", \"StudentsPerformance.csv\")\n",
    "MODEL_DIR = os.path.join(\"..\", \"models\")\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Using data path:\", DATA_PATH)\n",
    "print(\"Model directory:\", MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c95273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with flexible column handling\n",
    "def load_data(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Dataset not found at {path}. Please place 'StudentsPerformance.csv' in the data/ directory.\"\n",
    "        )\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Try to standardize expected column names\n",
    "    # Common variants seen across datasets\n",
    "    col_map = {\n",
    "        \"math score\": [\"math score\",\"math_score\",\"math\",\"maths\",\"MathScore\",\"mathscore\"],\n",
    "        \"reading score\": [\"reading score\",\"reading_score\",\"reading\",\"ReadingScore\",\"readingscore\"],\n",
    "        \"writing score\": [\"writing score\",\"writing_score\",\"writing\",\"WritingScore\",\"writingscore\"],\n",
    "        \"gender\": [\"gender\",\"Gender\"],\n",
    "        \"race/ethnicity\": [\"race/ethnicity\",\"race\",\"ethnicity\",\"RaceEthnicity\"],\n",
    "        \"parental level of education\": [\"parental level of education\",\"parental_level_of_education\",\"parental education\",\"parental_education\"],\n",
    "        \"lunch\": [\"lunch\",\"Lunch\"],\n",
    "        \"test preparation course\": [\"test preparation course\",\"test_prep\",\"test preparation\",\"test_preparation_course\"],\n",
    "    }\n",
    "    lower_cols = {c.lower(): c for c in df.columns}\n",
    "    new_cols = {}\n",
    "    for std, variants in col_map.items():\n",
    "        found = None\n",
    "        for v in variants:\n",
    "            if v.lower() in lower_cols:\n",
    "                found = lower_cols[v.lower()]\n",
    "                break\n",
    "        if found is not None:\n",
    "            new_cols[found] = std\n",
    "    df = df.rename(columns=new_cols)\n",
    "\n",
    "    required = [\"math score\",\"reading score\",\"writing score\",\"gender\",\"race/ethnicity\",\"parental level of education\",\"lunch\",\"test preparation course\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns after mapping: {missing}. Please update the mapping above to match your dataset.\")\n",
    "    return df\n",
    "\n",
    "df = load_data(DATA_PATH)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd60796",
   "metadata": {},
   "source": [
    "## Quick EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e76dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.describe(include='all').T.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d1f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots for scores\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.hist(df[\"math score\"].dropna(), bins=20)\n",
    "plt.title(\"Math Score Distribution\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.hist(df[\"reading score\"].dropna(), bins=20)\n",
    "plt.title(\"Reading Score Distribution\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.hist(df[\"writing score\"].dropna(), bins=20)\n",
    "plt.title(\"Writing Score Distribution\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ad4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "df[\"average_score\"] = df[[\"math score\",\"reading score\",\"writing score\"]].mean(axis=1)\n",
    "df[\"pass_fail\"] = (df[\"average_score\"] >= 60).astype(int)  # simple rule; adjust as needed\n",
    "\n",
    "df[[\"math score\",\"reading score\",\"writing score\",\"average_score\",\"pass_fail\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74d4812",
   "metadata": {},
   "source": [
    "## Train/Test Split & Preprocessing\n",
    "We'll predict **average_score** (regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3a0b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"average_score\"\n",
    "num_features = [\"math score\",\"reading score\",\"writing score\"]\n",
    "cat_features = [\"gender\",\"race/ethnicity\",\"parental level of education\",\"lunch\",\"test preparation course\"]\n",
    "\n",
    "X = df[cat_features + num_features].copy()\n",
    "y = df[target].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features),\n",
    "        (\"num\", \"passthrough\", num_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline([(\"pre\", pre), (\"model\", model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pred = pipe.predict(X_test)\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    rmse = mean_squared_error(y_test, pred, squared=False)\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    results[name] = {\"R2\": r2, \"RMSE\": rmse, \"MAE\": mae}\n",
    "\n",
    "pd.DataFrame(results).T.sort_values(\"R2\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e5a680",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "We'll tune the top-performing tree models with `RandomizedSearchCV` for speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b779a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "\n",
    "best_pipe = None\n",
    "best_score = -np.inf\n",
    "best_name = None\n",
    "\n",
    "# RandomForest tuning\n",
    "rf = Pipeline([(\"pre\", pre), (\"model\", RandomForestRegressor(random_state=42))])\n",
    "rf_params = {\n",
    "    \"model__n_estimators\": randint(100, 600),\n",
    "    \"model__max_depth\": randint(3, 20),\n",
    "    \"model__min_samples_split\": randint(2, 20),\n",
    "    \"model__min_samples_leaf\": randint(1, 10),\n",
    "}\n",
    "rf_search = RandomizedSearchCV(rf, rf_params, n_iter=25, scoring=\"r2\", cv=5, random_state=42, n_jobs=-1)\n",
    "rf_search.fit(X_train, y_train)\n",
    "rf_r2 = rf_search.best_score_\n",
    "if rf_r2 > best_score:\n",
    "    best_score = rf_r2\n",
    "    best_pipe = rf_search.best_estimator_\n",
    "    best_name = \"RandomForest\"\n",
    "\n",
    "# GradientBoosting tuning\n",
    "gb = Pipeline([(\"pre\", pre), (\"model\", GradientBoostingRegressor(random_state=42))])\n",
    "gb_params = {\n",
    "    \"model__n_estimators\": randint(100, 500),\n",
    "    \"model__learning_rate\": uniform(0.01, 0.3),\n",
    "    \"model__max_depth\": randint(2, 6),\n",
    "    \"model__subsample\": uniform(0.6, 0.4),\n",
    "}\n",
    "gb_search = RandomizedSearchCV(gb, gb_params, n_iter=25, scoring=\"r2\", cv=5, random_state=42, n_jobs=-1)\n",
    "gb_search.fit(X_train, y_train)\n",
    "gb_r2 = gb_search.best_score_\n",
    "if gb_r2 > best_score:\n",
    "    best_score = gb_r2\n",
    "    best_pipe = gb_search.best_estimator_\n",
    "    best_name = \"GradientBoosting\"\n",
    "\n",
    "print(\"Best CV R2:\", round(best_score, 4), \"Best Model:\", best_name)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = best_pipe.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "test_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "test_mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Test R2:\", round(test_r2, 4))\n",
    "print(\"Test RMSE:\", round(test_rmse, 4))\n",
    "print(\"Test MAE:\", round(test_mae, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f0b70f",
   "metadata": {},
   "source": [
    "## Feature Importance (Tree Models)\n",
    "We can inspect feature importances for interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738cebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature names after preprocessing\n",
    "ohe = best_pipe.named_steps[\"pre\"].named_transformers_[\"cat\"]\n",
    "ohe_features = list(ohe.get_feature_names_out(cat_features))\n",
    "all_features = ohe_features + num_features\n",
    "\n",
    "model = best_pipe.named_steps[\"model\"]\n",
    "if hasattr(model, \"feature_importances_\"):\n",
    "    importances = pd.Series(model.feature_importances_, index=all_features).sort_values(ascending=False)\n",
    "    print(importances.head(15))\n",
    "\n",
    "    # Plot top 15\n",
    "    topk = importances.head(15)\n",
    "    fig = plt.figure(figsize=(8,5))\n",
    "    topk[::-1].plot(kind=\"barh\")\n",
    "    plt.title(\"Top 15 Feature Importances\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Selected best model does not expose feature_importances_.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2b947e",
   "metadata": {},
   "source": [
    "## Persist Model\n",
    "Save the trained pipeline for use in the Streamlit app.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c144f08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(MODEL_DIR, \"best_model.pkl\")\n",
    "joblib.dump(best_pipe, model_path)\n",
    "model_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ceaee0",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "- Created `average_score` target and trained multiple models.\n",
    "- Tuned tree-based models with randomized search.\n",
    "- Saved the best pipeline and used it in a Streamlit app.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
